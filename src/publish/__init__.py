"""å‘å¸ƒæ¨¡å—"""

from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

from ..ingest.models import Item
from ..utils.logger import get_logger

logger = get_logger("publish")


def generate_daily_report(
    items: List[Item], output_dir: str, date: datetime, config: Dict[str, Any]
) -> str:
    """ç”Ÿæˆæ—¥æŠ¥

    Args:
        items: Itemåˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        date: æ—¥æœŸ
        config: è¾“å‡ºé…ç½®

    Returns:
        è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    logger.info(f"å¼€å§‹ç”Ÿæˆæ—¥æŠ¥: {len(items)} æ¡æ•°æ®")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶å
    filename = f"{date.strftime('%Y-%m-%d')}.md"
    filepath = output_path / filename

    # æŒ‰é…ç½®ç­›é€‰
    max_items = config.get("max_items", 40)
    min_score = config.get("min_score", 40)

    # è¿‡æ»¤ä½åˆ†
    items = [item for item in items if item.score >= min_score]

    # é™åˆ¶æ•°é‡
    items = items[:max_items]

    # åˆ†ç»„
    must_read_items = [item for item in items if item.is_must_read]
    regular_items = [item for item in items if not item.is_must_read]

    # æŒ‰ä¸»é¢˜åˆ†ç»„
    items_by_topic = defaultdict(list)
    for item in regular_items:
        if item.tags:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ ‡ç­¾ä½œä¸ºä¸»é¢˜
            items_by_topic[item.tags[0]].append(item)
        else:
            items_by_topic["å…¶ä»–"].append(item)

    # ç”ŸæˆMarkdown
    md_content = _generate_daily_markdown(
        date, must_read_items, items_by_topic, len(items), config
    )

    # å†™å…¥æ–‡ä»¶
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(md_content)

    logger.info(f"æ—¥æŠ¥å·²ç”Ÿæˆ: {filepath}")

    return str(filepath)


def _generate_daily_markdown(
    date: datetime,
    must_read_items: List[Item],
    items_by_topic: Dict[str, List[Item]],
    total_count: int,
    config: Dict[str, Any],
) -> str:
    """ç”Ÿæˆæ—¥æŠ¥Markdownå†…å®¹

    Args:
        date: æ—¥æœŸ
        must_read_items: å¿…è¯»åˆ—è¡¨
        items_by_topic: æŒ‰ä¸»é¢˜åˆ†ç»„çš„Item
        total_count: æ€»æ•°
        config: è¾“å‡ºé…ç½®

    Returns:
        Markdownå­—ç¬¦ä¸²
    """
    lines = []

    # Header
    lines.append(f"# AIä¿¡æ¯æ—¥æŠ¥ - {date.strftime('%Y-%m-%d')}")
    lines.append("")
    est_reading_time = total_count * 0.3  # æ¯æ¡çº¦0.3åˆ†é’Ÿ
    lines.append(
        f"ğŸ“Š æ€»è®¡: {total_count}æ¡ | ğŸ”¥ å¿…è¯»: {len(must_read_items)}æ¡ | â° é¢„è®¡é˜…è¯»: {int(est_reading_time)}åˆ†é’Ÿ"
    )
    lines.append("")
    lines.append("---")
    lines.append("")

    # Must Read Section
    if must_read_items:
        lines.append("## ğŸ”¥ å¿…è¯» (Must Read)")
        lines.append("")

        for item in must_read_items:
            lines.extend(_format_item(item, config))

        lines.append("---")
        lines.append("")

    # Topic Sections
    for topic, items in sorted(items_by_topic.items(), key=lambda x: -len(x[1])):
        # è·å–ä¸»é¢˜çš„display_nameï¼ˆå¦‚æœæœ‰ï¼‰
        lines.append(f"## ğŸ“š {topic}")
        lines.append("")

        for item in items:
            lines.extend(_format_item(item, config))

        lines.append("")

    return "\n".join(lines)


def _format_item(item: Item, config: Dict[str, Any]) -> List[str]:
    """æ ¼å¼åŒ–å•ä¸ªItem

    Args:
        item: Item
        config: è¾“å‡ºé…ç½®

    Returns:
        Markdownè¡Œåˆ—è¡¨
    """
    lines = []
    markdown_config = config.get("markdown", {})

    # æ ‡é¢˜å’Œé“¾æ¥
    lines.append(f"### [{item.title}]({item.url})")

    # å…ƒä¿¡æ¯
    pub_date = item.published.strftime("%Y-%m-%d %H:%M")
    score_str = f"{item.score:.0f}/100"
    meta = f"- **æ¥æº**: {item.source} | **å‘å¸ƒ**: {pub_date} | **è¯„åˆ†**: {score_str}"
    lines.append(meta)

    # æ‘˜è¦
    summary = item.ai_summary or item.summary or item.title
    lines.append(f"- **æ‘˜è¦**: {summary}")

    # å·¥ç¨‹å¸ˆè¦ç‚¹
    if item.key_points and markdown_config.get("include_action", True):
        lines.append("- **å·¥ç¨‹å¸ˆè¦ç‚¹**:")
        for point in item.key_points:
            lines.append(f"  - {point}")

    # è¡ŒåŠ¨å»ºè®®
    if item.action and markdown_config.get("include_action", True):
        lines.append(f"- **è¡ŒåŠ¨å»ºè®®**: {item.action}")

    # è¯„åˆ†è¯¦è§£
    if markdown_config.get("include_score_breakdown", True) and item.score_breakdown:
        breakdown = item.score_breakdown
        reasons = breakdown.get("reasons", [])
        if reasons:
            reason_text = " | ".join(reasons[:3])  # æœ€å¤šæ˜¾ç¤º3æ¡
            lines.append(f"- **è¯„åˆ†è¯¦è§£**: {reason_text}")

    lines.append("")

    return lines


def generate_weekly_report(
    items: List[Item], output_dir: str, week_start: datetime, config: Dict[str, Any]
) -> str:
    """ç”Ÿæˆå‘¨æŠ¥

    Args:
        items: Itemåˆ—è¡¨ï¼ˆä¸€å‘¨å†…çš„ï¼‰
        output_dir: è¾“å‡ºç›®å½•
        week_start: å‘¨å¼€å§‹æ—¥æœŸ
        config: è¾“å‡ºé…ç½®

    Returns:
        è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    logger.info(f"å¼€å§‹ç”Ÿæˆå‘¨æŠ¥: {len(items)} æ¡æ•°æ®")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶å (ISOå‘¨å·)
    year, week_num, _ = week_start.isocalendar()
    filename = f"{year}-W{week_num:02d}.md"
    filepath = output_path / filename

    # æŒ‰é…ç½®ç­›é€‰
    max_items = config.get("max_items", 120)
    min_score = config.get("min_score", 50)

    # è¿‡æ»¤ä½åˆ†
    items = [item for item in items if item.score >= min_score]

    # é™åˆ¶æ•°é‡
    items = items[:max_items]

    # ç”ŸæˆMarkdown
    md_content = _generate_weekly_markdown(week_start, items, config)

    # å†™å…¥æ–‡ä»¶
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(md_content)

    logger.info(f"å‘¨æŠ¥å·²ç”Ÿæˆ: {filepath}")

    return str(filepath)


def _generate_weekly_markdown(
    week_start: datetime, items: List[Item], config: Dict[str, Any]
) -> str:
    """ç”Ÿæˆå‘¨æŠ¥Markdownå†…å®¹

    Args:
        week_start: å‘¨å¼€å§‹æ—¥æœŸ
        items: Itemåˆ—è¡¨
        config: è¾“å‡ºé…ç½®

    Returns:
        Markdownå­—ç¬¦ä¸²
    """
    lines = []

    year, week_num, _ = week_start.isocalendar()

    # Header
    lines.append(f"# AIä¿¡æ¯å‘¨æŠ¥ - {year} W{week_num:02d}")
    lines.append("")

    # æœ¬å‘¨æ€»è§ˆ
    lines.append("## æœ¬å‘¨æ€»è§ˆ")
    lines.append("")
    overview = _generate_overview(items)
    lines.append(overview)
    lines.append("")
    lines.append("---")
    lines.append("")

    # æœ¬å‘¨è¶‹åŠ¿ Top 5
    trend_count = config.get("trend_count", 5)
    trends = _extract_trends(items, trend_count)

    lines.append(f"## ğŸ”¥ æœ¬å‘¨è¶‹åŠ¿ Top {trend_count}")
    lines.append("")

    for i, trend in enumerate(trends, 1):
        lines.append(f"### {i}. {trend['title']}")
        lines.append("")
        for item in trend["items"]:
            lines.append(f"- [{item.title}]({item.url})")
        lines.append(f"**è¶‹åŠ¿**: {trend['description']}")
        lines.append("")

    lines.append("---")
    lines.append("")

    # æœ¬å‘¨å¿…åš Top 3
    must_do_count = config.get("must_do_count", 3)
    must_dos = _extract_must_dos(items, must_do_count)

    lines.append(f"## âœ… æœ¬å‘¨å¿…åš Top {must_do_count}")
    lines.append("")

    for i, item in enumerate(must_dos, 1):
        lines.append(f"{i}. **{item.action or 'å…³æ³¨æ­¤æ›´æ–°'}**: {item.title} - {item.source}")

    lines.append("")
    lines.append("---")
    lines.append("")

    # ä¸‹å‘¨å…³æ³¨æ¸…å•
    watchlist_count = config.get("watchlist_count", 5)
    watchlist = _generate_watchlist(items, watchlist_count)

    lines.append("## ğŸ‘€ ä¸‹å‘¨å…³æ³¨æ¸…å•")
    lines.append("")

    for item in watchlist:
        lines.append(f"- [ ] {item}")

    lines.append("")

    return "\n".join(lines)


def _generate_overview(items: List[Item]) -> str:
    """ç”Ÿæˆæœ¬å‘¨æ€»è§ˆ

    Args:
        items: Itemåˆ—è¡¨

    Returns:
        æ€»è§ˆæ–‡æœ¬
    """
    # ç»Ÿè®¡ä¸»é¢˜åˆ†å¸ƒ
    tag_counts = defaultdict(int)
    for item in items:
        for tag in item.tags:
            tag_counts[tag] += 1

    top_topics = sorted(tag_counts.items(), key=lambda x: -x[1])[:5]
    topics_text = "ã€".join([f"{t[0]}({t[1]}æ¡)" for t in top_topics])

    # ç»Ÿè®¡é«˜åˆ†æ¡ç›®
    high_score_count = len([item for item in items if item.score >= 80])

    overview = f"æœ¬å‘¨å…±é‡‡é›† {len(items)} æ¡AIé¢†åŸŸä¿¡æ¯ï¼Œé«˜åˆ†æ¡ç›®(scoreâ‰¥80) {high_score_count} æ¡ã€‚"
    overview += f"ä¸»è¦ä¸»é¢˜åŒ…æ‹¬: {topics_text}ã€‚"

    return overview


def _extract_trends(items: List[Item], count: int) -> List[Dict[str, Any]]:
    """æå–è¶‹åŠ¿

    Args:
        items: Itemåˆ—è¡¨
        count: è¶‹åŠ¿æ•°é‡

    Returns:
        è¶‹åŠ¿åˆ—è¡¨
    """
    # æŒ‰ä¸»é¢˜èšåˆ
    topic_items = defaultdict(list)
    for item in items:
        for tag in item.tags:
            topic_items[tag].append(item)

    # è®¡ç®—æ¯ä¸ªä¸»é¢˜çš„æ€»åˆ†
    topic_scores = {
        topic: sum(item.score for item in items_list)
        for topic, items_list in topic_items.items()
    }

    # Top Nä¸»é¢˜
    top_topics = sorted(topic_scores.items(), key=lambda x: -x[1])[:count]

    trends = []
    for topic, _ in top_topics:
        items_list = topic_items[topic]
        # å–è¯¥ä¸»é¢˜ä¸‹æœ€é«˜åˆ†çš„3æ¡
        top_items = sorted(items_list, key=lambda x: -x.score)[:3]

        # ç”Ÿæˆè¶‹åŠ¿æè¿°
        description = f"{topic}é¢†åŸŸæœ¬å‘¨å…±{len(items_list)}æ¡æ›´æ–°ï¼Œé‡ç‚¹å…³æ³¨ä¸Šè¿°è¿›å±•"

        trends.append(
            {
                "title": topic,
                "items": top_items,
                "description": description,
            }
        )

    return trends


def _extract_must_dos(items: List[Item], count: int) -> List[Item]:
    """æå–å¿…åšäº‹é¡¹

    Args:
        items: Itemåˆ—è¡¨
        count: æ•°é‡

    Returns:
        å¿…åšItemåˆ—è¡¨
    """
    # ä¼˜å…ˆé€‰æ‹©must_read + é«˜åˆ† + æœ‰æ˜ç¡®actionçš„
    must_read = [item for item in items if item.is_must_read and item.action]

    # æŒ‰åˆ†æ•°æ’åº
    must_read.sort(key=lambda x: -x.score)

    return must_read[:count]


def _generate_watchlist(items: List[Item], count: int) -> List[str]:
    """ç”Ÿæˆå…³æ³¨æ¸…å•

    Args:
        items: Itemåˆ—è¡¨
        count: æ•°é‡

    Returns:
        å…³æ³¨æ¸…å•æ–‡æœ¬åˆ—è¡¨
    """
    # æå–å¯èƒ½åœ¨ä¸‹å‘¨æœ‰åç»­çš„äº‹é¡¹
    watchlist = []

    keywords = ["upcoming", "soon", "next", "beta", "rc", "preview", "roadmap"]

    for item in items:
        text = (item.title + " " + (item.summary or "")).lower()
        if any(kw in text for kw in keywords):
            watchlist.append(f"{item.source}: {item.title}")

    # å¦‚æœä¸è¶³ï¼Œè¡¥å……é«˜åˆ†æ¡ç›®
    if len(watchlist) < count:
        high_score = sorted(items, key=lambda x: -x.score)
        for item in high_score:
            entry = f"{item.source}: {item.title}"
            if entry not in watchlist:
                watchlist.append(entry)
            if len(watchlist) >= count:
                break

    return watchlist[:count]


__all__ = ["generate_daily_report", "generate_weekly_report"]
